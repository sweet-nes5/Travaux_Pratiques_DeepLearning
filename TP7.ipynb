{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "720c98c7-e4f5-42cc-bb0c-32bc39313a25",
   "metadata": {},
   "source": [
    "## Exercice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09047ec7-5286-45dc-ba0a-adb11a67e0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19571ded-a58c-467d-885f-5b7ae69d8f2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/nesrine/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so: undefined symbol: ncclCommRegister",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, Subset\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/__init__.py:237\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[1;32m    236\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# torch._C module initialization code in C\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[0;31mImportError\u001b[0m: /home/nesrine/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so: undefined symbol: ncclCommRegister"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "root_dir = '/home/nesrine/Bureau/DeepLearning/cifar10_data'\n",
    "\n",
    "#training data\n",
    "train_data = datasets.CIFAR10(\n",
    "    root=root_dir, \n",
    "    train=True, # we specify train = true to indicate that it is a training a set\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True)\n",
    "#validation/test data\n",
    "validation_data = datasets.CIFAR10(\n",
    "    root=root_dir, \n",
    "    train=False, #and here it is a testing set\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True)\n",
    "\n",
    "labels_dict ={\n",
    "    0: \"plane\",\n",
    "    1: \"car\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226e02c1-0c0e-4f2b-8352-0a66e05bea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des cinq premières images avec leurs étiquettes\n",
    "for i in range(5):\n",
    "    image, label = train_data[i]\n",
    "    print(f\"Image{i+1} :\")\n",
    "    print(\"Shape :\",image.shape)\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.title(labels_dict[label])\n",
    "    plt.axis('on')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e57c55-c80f-44bd-a96d-c6e30c310b6e",
   "metadata": {},
   "source": [
    "## Exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e899e-7beb-4cc7-9a7b-22dde2e75c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=(5,5))\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(5,5))\n",
    "        self.conv3 = nn.Conv2d(16, 120, kernel_size=(5,5))\n",
    "        self.fc1 = nn.Linear(120,84)\n",
    "        self.fc2 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self,input):\n",
    "        layer1 = F.relu(self.conv1(input))\n",
    "        layer2 = F.max_pool2d(layer1, kernel_size=(2,2), stride=2)\n",
    "        layer3 = F.relu(self.conv2(layer2))\n",
    "        layer4 = F.max_pool2d(layer3, kernel_size=(2,2), stride=2)\n",
    "        layer5 = F.relu(self.conv3(layer4))\n",
    "        layer6 = F.relu(self.fc1(torch.flatten(layer5,1)))\n",
    "        layer7 = self.fc2(layer6)\n",
    "        return layer7\n",
    "\n",
    "\n",
    "model = LeNet5()\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters in model:\", num_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe12a3-9939-450d-bb1a-3e8d3784bc25",
   "metadata": {},
   "source": [
    "## Exercice 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca0dca1-b302-4aa1-94a5-01b5129b63fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions_proba, targets, top=5):\n",
    "    tensor_top = torch.topk(predictions_proba, top).indices\n",
    "    # warning, not yet efficiently implemented\n",
    "    good_predictions = functorch.vmap(lambda t1, t2: torch.isin(t1,t2))(targets, tensor_top)\n",
    "    return (good_predictions).sum()/len(targets) * 100\n",
    "\n",
    "# Plot monitoring\n",
    "def ith(l, i):\n",
    "    return [x[i] for x in l]\n",
    "\n",
    "def plot_history(h):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    axs[0].plot(ith(h,0), ith(h,1))\n",
    "    axs[0].plot(ith(h,0), ith(h,3), color='red')\n",
    "    axs[0].set_xlabel('epochs')\n",
    "    axs[0].set_ylabel('loss')\n",
    "    axs[1].plot(ith(h,0), ith(h,2))\n",
    "    axs[1].plot(ith(h,0), ith(h,4), color='red')\n",
    "    axs[1].set_xlabel('epochs')\n",
    "    axs[1].set_ylabel('accuracy')\n",
    "    fig.suptitle('Monitor learning')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# subset des données\n",
    "train_subset = Subset(train_data, range(500))\n",
    "validation_subset = Subset(validation_data, range(500))\n",
    "\n",
    "# training and validation loaders for mini batch\n",
    "train_loader = DataLoader(train_subset, batch_size=256, shuffle=True)\n",
    "validation_loader = DataLoader(validation_subset, batch_size=256, shuffle = True)\n",
    "\n",
    "# fonction de perte\n",
    "CEL = nn.CrossEntropyLoss()\n",
    "\n",
    "def grad_des(epoch, model, optim):\n",
    "    history = []\n",
    "    train_inputs = []\n",
    "    train_labels = []\n",
    "    valid_inputs = []\n",
    "    valid_labels = []\n",
    "    \n",
    "    for inputs, targets in validation_loader:\n",
    "        valid_inputs.append(inputs)\n",
    "        valid_labels.append(targets)\n",
    "        \n",
    "        \n",
    "    for inputs_, guesses_ in train_loader:\n",
    "            train_inputs.append(inputs_)\n",
    "            train_labels.append(guesses_)\n",
    "\n",
    "    for ep in range(epoch):       \n",
    "        pred = model(train_inputs[ep%len(train_inputs)])\n",
    "        \n",
    "        err = CEL(pred, train_labels[ep%len(train_labels)])\n",
    "        model.zero_grad()\n",
    "        err.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if ep % 100 == 0:\n",
    "            acc = accuracy(pred, train_labels[ep%len(train_labels)])\n",
    "            acc_val = accuracy( model(valid_inputs[ep%len(valid_inputs)]), valid_labels[ep%len(valid_labels)])\n",
    "            pred = model(valid_inputs[ep%len(valid_inputs)])\n",
    "            loss_val = CEL(pred, valid_labels[ep%len(valid_labels)])\n",
    "            history.append((ep, err.detach().numpy(), acc, loss_val.detach().numpy(), acc_val))\n",
    "            print(f\"Loss at epoch {ep}: {err.item()} accuracy {acc} number of batch {ep%train_loader.batch_size}\")\n",
    "    \n",
    "    return history\n",
    "    \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "history = grad_des(500, model, optimizer)       \n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7476ff8e-b532-46c0-aff0-663abb3ad304",
   "metadata": {},
   "source": [
    "## Exercice 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7993d-738c-43b2-b284-7903527214a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9429db-74f1-4b89-af82-f7e24b884fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
